{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,\n",
    "             model_name=\"Llama3-8b-8192\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF to text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 67 0 (offset 0)\n",
      "Ignoring wrong pointing object 127 0 (offset 0)\n",
      "Ignoring wrong pointing object 130 0 (offset 0)\n",
      "Ignoring wrong pointing object 186 0 (offset 0)\n",
      "Ignoring wrong pointing object 198 0 (offset 0)\n",
      "Ignoring wrong pointing object 203 0 (offset 0)\n",
      "Ignoring wrong pointing object 218 0 (offset 0)\n",
      "Ignoring wrong pointing object 223 0 (offset 0)\n",
      "Ignoring wrong pointing object 232 0 (offset 0)\n",
      "Ignoring wrong pointing object 241 0 (offset 0)\n",
      "Ignoring wrong pointing object 250 0 (offset 0)\n",
      "Ignoring wrong pointing object 259 0 (offset 0)\n",
      "Ignoring wrong pointing object 269 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader('data/solar.pdf')\n",
    "\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages=[]\n",
    "len_words=0\n",
    "for i in range(len(documents)):\n",
    "    len_words=len_words+len(documents[i].page_content)\n",
    "    pages.append(documents[i].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template('''\n",
    "Your given a {list} of strings extracted from pdfs .\n",
    "\n",
    "And give the output of the of this in string if the string is greater than the context window of llm break it and conver into small parts But dont drop any information\n",
    "I want the output in the list fromat and i dont need your notes from starting to end only list and your losing the info initially i have more words but after this prompt you droped it . Dont drop anny kind of info  \n",
    "                                                                               \n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    " \"list\":pages    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response1 \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(\u001b[43mprompt\u001b[49m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minput_data))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prompt' is not defined"
     ]
    }
   ],
   "source": [
    "for response1 = llm.invoke(prompt.format(**input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5019\n"
     ]
    }
   ],
   "source": [
    "print(len(response1.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "para=  response1.content\n",
    "example= [\"The company started in 1990 as a small startup. Over the years, it grew into a multinational corporation.\", \"However, the growth brought challenges, particularly in maintaining company culture.\", \"Recently, the company has been investing heavily in sustainable practices. These efforts have started to show results, with a reduction in carbon footprint by 20%.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=ChatPromptTemplate.from_template(\n",
    " '''\n",
    "\n",
    "Given an input {para}, detect where the context shifts within the text. Each distinct context should be separated and stored as an individual item in a {list}. \n",
    "The output should be a list of strings, where each string represents a segment of the paragraph with a consistent context. or if the context is bigger of one para break into smaller parts  Ignore sentence boundaries that do not indicate a change in context, and \n",
    "focus only on separating the paragraph based on significant shifts in topic or meaning and match this output format from {example}. I only need the list of those paras not your notes if the the out\n",
    "if the elemnet from the list exceeds the 384 words please break the elemnt into smaller elemnts not exceeding the 384 limit\n",
    "Note: i dont need back slashes or any escape sequence and your staring note I only need a list \n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    \"para\": para,\n",
    "    \"list\": lst,\n",
    "    \"example\":example\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = llm.invoke(prompt2.format(**input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=response1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1660"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Planets are categorized as terrestrial and Jovian planets.',\n",
       " 'Terrestrial planets are small inner planets, Jovian planets are large outer planets.',\n",
       " 'Terrestrial planets are rocky, dense, made of heavy elements, Jovian planets are gaseous, made of hydrogen, helium, or ice.',\n",
       " 'All planets but Mercury and Venus have satellites.',\n",
       " 'Satellites orbit around planets, planets orbit around the Sun.',\n",
       " 'Asteroids are small rocky objects, comets are small icy objects.',\n",
       " 'Asteroids orbit in the asteroid belt between Mars and Jupiter, comets orbit in the Kuiper belt beyond Neptune.',\n",
       " 'Atmospheres are retained by gravity, temperature, and gas composition.',\n",
       " 'Planets with low mass, high temperature, and weak gravity lose gases, while planets with high mass, low temperature, and strong gravity retain gases.',\n",
       " 'Planetary magnetic fields are produced by motion of electrically conducting liquids inside the planet.',\n",
       " 'Terrestrial planets have magnetic fields produced by metals in the liquid state, Jovian planets have strong fields produced by liquid metallic hydrogen or ionized water.',\n",
       " 'Gravity and distance to the Sun are crucial in understanding the solar system.',\n",
       " 'Cratering on planets and satellites indicates impacts from interplanetary debris.',\n",
       " 'Presence of magnetic fields reflects motion of electrically conducting liquids inside the planets.']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def extract_list(text):\n",
    "    # Extract sections and list items using regex\n",
    "    sections = re.split(r'\\*\\*(.*?)\\*\\*', text)\n",
    "    \n",
    "    extracted_list = []\n",
    "    for section in sections:\n",
    "        if section.strip() and not section.startswith(\"After\"):\n",
    "            items = re.findall(r'\\d+\\.\\s(.+)', section)\n",
    "            extracted_list.extend(items)\n",
    "    \n",
    "    return extracted_list\n",
    "\n",
    "# Extract and print the list\n",
    "list_content = extract_list(x)\n",
    "list_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/de/anaconda3/envs/metlife/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/home/de/anaconda3/envs/metlife/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/de/anaconda3/envs/metlife/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 67 0 (offset 0)\n",
      "Ignoring wrong pointing object 127 0 (offset 0)\n",
      "Ignoring wrong pointing object 130 0 (offset 0)\n",
      "Ignoring wrong pointing object 186 0 (offset 0)\n",
      "Ignoring wrong pointing object 198 0 (offset 0)\n",
      "Ignoring wrong pointing object 203 0 (offset 0)\n",
      "Ignoring wrong pointing object 218 0 (offset 0)\n",
      "Ignoring wrong pointing object 223 0 (offset 0)\n",
      "Ignoring wrong pointing object 232 0 (offset 0)\n",
      "Ignoring wrong pointing object 241 0 (offset 0)\n",
      "Ignoring wrong pointing object 250 0 (offset 0)\n",
      "Ignoring wrong pointing object 259 0 (offset 0)\n",
      "Ignoring wrong pointing object 269 0 (offset 0)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Solar System Lecture 8 \\nThe Cassini  Jiong Qiu, MSU Physics Department '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metlife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
